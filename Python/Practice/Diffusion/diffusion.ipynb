{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d240267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "train_dataset=datasets.MNIST(root='./dataset',train=True,download=True,transform=transform)\n",
    "train_loader=DataLoader(train_dataset,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c01e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqrt_alphas_cumprod.shape:torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "T=300\n",
    "beta_start=1e-4\n",
    "beta_end=0.02\n",
    "betas=torch.linspace(beta_start,beta_end,T)\n",
    "\n",
    "alphas=1.-betas\n",
    "alphas_cumprod=torch.cumprod(alphas,dim=0)\n",
    "sqrt_alphas_cumprod=torch.sqrt(alphas_cumprod)\n",
    "sqrt_1minusalphas_cumprod=torch.sqrt(1-alphas_cumprod)\n",
    "\n",
    "print(f'sqrt_alphas_cumprod.shape:{sqrt_alphas_cumprod.shape}')\n",
    "\n",
    "def q_sample(x_start,t,noise=None):\n",
    "    if noise is None:\n",
    "        noises = torch.randn_like(x_start)\n",
    "    sqrt_alpha=sqrt_alphas_cumprod[t].view(-1,1,1,1)\n",
    "    sqrt_1minusalpha=sqrt_1minusalphas_cumprod[t].view(-1,1,1,1)\n",
    "    return x_start*sqrt_alpha+noise*sqrt_1minusalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ee51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(t, dim):\n",
    "    half_dim = dim // 2\n",
    "    emb=math.log(10000)/(half_dim-1)\n",
    "    emb=torch.exp(-emb*torch.arange(half_dim,device=t.device))\n",
    "    emb=t.float()[:,None]*emb[None,:]\n",
    "    emb=torch.cat([torch.sin(emb),torch.cos(emb)],dim=-1)\n",
    "    if dim % 2 == 1:  # odd embedding_dim\n",
    "        emb = F.pad(emb, (0,1))\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86bb07",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.functional' has no attribute 'mse_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m x_noisy=q_sample(x,t,noise)\n\u001b[32m     84\u001b[39m pred_noise=model(x_noisy,t)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m loss = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmse_loss\u001b[49m(pred_noise, noise)\n\u001b[32m     86\u001b[39m optimizer.zero_grad()\n\u001b[32m     87\u001b[39m loss.backward()\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch.functional' has no attribute 'mse_loss'"
     ]
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, base_channels=32, time_emb_dim=128):\n",
    "        super().__init__()\n",
    "        # 时间步嵌入MLP\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim, base_channels*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(base_channels*4, base_channels*4)\n",
    "        )\n",
    "        # 编码器\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_channels, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels, base_channels*2, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*2, base_channels*2, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*4, base_channels*4, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 解码器\n",
    "        self.up1 = nn.ConvTranspose2d(base_channels*4, base_channels*2, 2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*4, base_channels*2, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*2, base_channels*2, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.up2 = nn.ConvTranspose2d(base_channels*2, base_channels, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out_conv = nn.Conv2d(base_channels, out_channels, 1)\n",
    "\n",
    "        self.time_emb_dim = time_emb_dim\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # t: [batch] int64\n",
    "        t_emb = get_timestep_embedding(t, self.time_emb_dim)  # [batch, time_emb_dim]\n",
    "        t_emb = self.time_mlp(t_emb)  # [batch, base_channels*4]\n",
    "        # 编码\n",
    "        e1 = self.enc1(x)         # [B, C, 28, 28]\n",
    "        e2 = self.enc2(e1)        # [B, 2C, 14, 14]\n",
    "        e3 = self.enc3(e2)        # [B, 4C, 7, 7]\n",
    "        # 加时间步嵌入到bottleneck\n",
    "        t_emb = t_emb[:, :, None, None]  # [B, 4C, 1, 1]\n",
    "        e3 = e3 + t_emb\n",
    "        # 解码\n",
    "        d1 = self.up1(e3)         # [B, 2C, 14, 14]\n",
    "        d1 = torch.cat([d1, e2], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        d2 = self.up2(d1)         # [B, C, 28, 28]\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        out = self.out_conv(d2)\n",
    "        return out\n",
    "\n",
    "model=UNet().to(device)\n",
    "optimizer=optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "epochs=10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x,_ in train_loader:\n",
    "        x=x.to(device)\n",
    "        batch_size=x.size(0)\n",
    "        t=torch.randint(0,T,(batch_size,),device=device,).long()\n",
    "        noise=torch.randn_like(x)\n",
    "        x_noisy=q_sample(x,t,noise)\n",
    "        pred_noise=model(x_noisy,t)\n",
    "        loss=F.mse_loss(pred_noise,noise)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n",
    "\n",
    "torch.save(model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
