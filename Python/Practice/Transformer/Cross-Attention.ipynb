{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5d1aadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "eea8a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self,vocab_size,d_model):\n",
    "        super(TokenEmbedding,self).__init__(vocab_size,d_model,padding_idx=1)\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self,d_model,max_len,device):\n",
    "        super(PositionalEmbedding,self).__init__()\n",
    "        self.encoding=torch.zeros(max_len,d_model,device=device)\n",
    "        self.encoding.requires_grad=False\n",
    "        pos=torch.arange(0,max_len,device=device)\n",
    "        pos=pos.float().unsqueeze(dim=1)\n",
    "        _2i=torch.arange(0,d_model,step=2,device=device).float()\n",
    "        self.encoding[:,0::2]=torch.sin(pos/(10000**(_2i/d_model)))\n",
    "        self.encoding[:,1::2]=torch.cos(pos/(10000**(_2i/d_model)))\n",
    "    def forward(self,x):\n",
    "        seq_len=x.size(1)\n",
    "        return self.encoding[:seq_len,:]\n",
    "\n",
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size,d_model,max_len,dropout,device):\n",
    "        super().__init__()\n",
    "        self.tokenEmbedding=TokenEmbedding(vocab_size,d_model)\n",
    "        self.positionalEmbedding=PositionalEmbedding(d_model,max_len,device)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        tokenEmb=self.tokenEmbedding(x)\n",
    "        posEmb=self.positionalEmbedding(x)\n",
    "        out=tokenEmb+posEmb\n",
    "        return self.dropout(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ffa127bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttension(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,Q,K,V,mask=None):\n",
    "        d_k=Q.size(-1)\n",
    "        scores=torch.matmul(Q,K.transpose(-1,-2))/math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn=torch.softmax(scores,dim=-1)\n",
    "        output=torch.matmul(attn,V)\n",
    "        return output,attn\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_model,num_heads,dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model%num_heads==0\n",
    "        self.num_heads=num_heads\n",
    "        self.d_model=d_model\n",
    "        self.d_k=d_model//num_heads\n",
    "        self.linear_Q=nn.Linear(d_model,d_model)\n",
    "        self.linear_K=nn.Linear(d_model,d_model)\n",
    "        self.linear_V=nn.Linear(d_model,d_model)\n",
    "        self.attention=ScaledDotProductAttension()\n",
    "        self.linear_out=nn.Linear(d_model,d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,Q,K,V,mask=None):\n",
    "        batch_size=Q.size(0)\n",
    "        Q=self.linear_Q(Q).view(batch_size,-1,self.num_heads,self.d_k).permute(0,2,1,3)\n",
    "        K=self.linear_K(K).view(batch_size,-1,self.num_heads,self.d_k).permute(0,2,1,3)\n",
    "        V=self.linear_V(V).view(batch_size,-1,self.num_heads,self.d_k).permute(0,2,1,3)\n",
    "\n",
    "        out,attn=self.attention(Q,K,V,mask)\n",
    "        out=out.transpose(1,2).contiguous().view(batch_size,-1,self.num_heads*self.d_k)\n",
    "        out=self.linear_out(out)\n",
    "        out=self.dropout(out)\n",
    "        return out,attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ef3a5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,normalized_shape,eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps=eps\n",
    "        self.gamma=nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.beta=nn.Parameter(torch.zeros(normalized_shape))\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(dim=-1,keepdim=True)\n",
    "        var=x.var(dim=-1,keepdim=True)\n",
    "        x_norm=(x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.gamma*x_norm+self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7305cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeLayer(nn.Module):\n",
    "    def __init__(self,d_model,num_heads,d_ff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.multiHeadAttention=MultiHeadAttention(d_model,num_heads)\n",
    "        self.norm1=LayerNorm(d_model)\n",
    "        self.ff=nn.Sequential(\n",
    "            nn.Linear(d_model,d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff,d_model)\n",
    "        )\n",
    "        self.norm2=LayerNorm(d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    def forward(self,x,mask=None):\n",
    "        attn_out,out=self.multiHeadAttention(x,x,x,mask)\n",
    "        x=self.norm1(x+self.dropout(attn_out))\n",
    "        ff_out=self.ff(x)\n",
    "        x=self.norm2(x+self.dropout(ff_out))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,num_layers,d_model,num_heads,d_ff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers=nn.ModuleList([\n",
    "            EncodeLayer(d_model,num_heads,d_ff,dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "    def forward(self,x,mask=None):\n",
    "        for layer in self.layers:\n",
    "            x=layer(x,mask)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "aa040d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeLayer(nn.Module):\n",
    "    def __init__(self,d_model,num_heads,d_ff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.maskedMultiHeadAttention=MultiHeadAttention(d_model,num_heads)\n",
    "        self.multiHeadAttention=MultiHeadAttention(d_model,num_heads)\n",
    "        self.norm1=LayerNorm(d_model)\n",
    "        self.norm2=LayerNorm(d_model)\n",
    "        self.norm3=LayerNorm(d_model)\n",
    "        self.ff=nn.Sequential(\n",
    "            nn.Linear(d_model,d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff,d_model)\n",
    "        )\n",
    "        self.dropout=nn.Dropout()\n",
    "\n",
    "    def forward(self,x,encoder_output,tgt_mask,memory_mask):\n",
    "        out1,_=self.maskedMultiHeadAttention(x,x,x,tgt_mask)\n",
    "        x=self.norm1(x+self.dropout(out1))\n",
    "        out2,_=self.multiHeadAttention(x,encoder_output,x,memory_mask)\n",
    "        x=self.norm2(x+self.dropout(out2))\n",
    "        out3=self.ff(x)\n",
    "        x=self.norm3(x+self.dropout(out3))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,num_layers,d_model,num_heads,d_ff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecodeLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self,x,encoder_output,tgt_mask=None,memery_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x=layer(x,encoder_output,tgt_mask,memery_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ff70596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size,d_model,max_len,num_layers,num_heads,d_ff,dropout,device):\n",
    "        super().__init__()\n",
    "        self.embedding=TransformerEmbedding(vocab_size,d_model,max_len,dropout,device)\n",
    "        self.encoder=Encoder(num_layers,d_model,num_heads,d_ff,dropout)\n",
    "        self.decoder=Decoder(num_layers,d_model,num_heads,d_ff,dropout)\n",
    "        self.output_layer=nn.Linear(d_model,vocab_size)\n",
    "\n",
    "    def forward(self,src,tgt,src_mask=None,tgt_mask=None,memery_mask=None):\n",
    "        src_emb=self.embedding(src)\n",
    "        tgt_emb=self.embedding(tgt)\n",
    "        memory=self.encoder(src_emb,src_mask)\n",
    "        out=self.decoder(tgt_emb,memory,tgt_mask,memery_mask)\n",
    "        logits=self.output_layer(out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d122a576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集英文样本数: 29000\n",
      "训练集德文样本数: 29000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "DATASET_PATH = \"./dataset/data/task1/raw\"\n",
    "\n",
    "def load_data(file_path):\n",
    "    with gzip.open(file_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        return f.readlines() \n",
    "\n",
    "train_en = load_data(os.path.join(DATASET_PATH, \"train.en.gz\"))\n",
    "train_de = load_data(os.path.join(DATASET_PATH, \"train.de.gz\"))\n",
    "val_en = load_data(os.path.join(DATASET_PATH, \"val.en.gz\"))\n",
    "val_de = load_data(os.path.join(DATASET_PATH, \"val.de.gz\"))\n",
    "test_en = load_data(os.path.join(DATASET_PATH, \"test_2017_flickr.en.gz\"))\n",
    "test_de = load_data(os.path.join(DATASET_PATH, \"test_2017_flickr.de.gz\"))\n",
    "\n",
    "print(f\"训练集英文样本数: {len(train_en)}\")\n",
    "print(f\"训练集德文样本数: {len(train_de)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "35dc349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def compute_bleu(candidate, references, max_n=4):\n",
    "    \"\"\"\n",
    "    计算 BLEU 分数\n",
    "    :param candidate: 模型生成的翻译结果（列表）\n",
    "    :param references: 参考翻译（列表的列表）\n",
    "    :param max_n: 最大 n-gram\n",
    "    :return: BLEU 分数\n",
    "    \"\"\"\n",
    "    weights = [1.0 / max_n] * max_n  # 平均权重\n",
    "    p_n = [0] * max_n\n",
    "    candidate_len = len(candidate)\n",
    "    reference_lens = [len(ref) for ref in references]\n",
    "    \n",
    "    # 计算 n-gram 精确度\n",
    "    for n in range(1, max_n + 1):\n",
    "        candidate_ngrams = Counter([tuple(candidate[i:i+n]) for i in range(len(candidate) - n + 1)])\n",
    "        max_counts = Counter()\n",
    "        for ref in references:\n",
    "            ref_ngrams = Counter([tuple(ref[i:i+n]) for i in range(len(ref) - n + 1)])\n",
    "            for ngram in candidate_ngrams:\n",
    "                max_counts[ngram] = max(max_counts[ngram], ref_ngrams[ngram])\n",
    "        clipped_counts = {ngram: min(count, max_counts[ngram]) for ngram, count in candidate_ngrams.items()}\n",
    "        p_n[n-1] = sum(clipped_counts.values()) / max(1, sum(candidate_ngrams.values()))\n",
    "    \n",
    "    # BP（brevity penalty）计算\n",
    "    closest_ref_len = min(reference_lens, key=lambda ref_len: abs(ref_len - candidate_len))\n",
    "    bp = math.exp(1 - closest_ref_len / candidate_len) if candidate_len < closest_ref_len else 1.0\n",
    "    \n",
    "    # BLEU 分数计算\n",
    "    bleu = bp * math.exp(sum(w * math.log(p) for w, p in zip(weights, p_n) if p > 0))\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3926691e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[24, -1, 8, 64]' is invalid for input of size 409600",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[184], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 91\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[184], line 81\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     79\u001b[0m tgt_output \u001b[38;5;241m=\u001b[39m tgt_batch[\u001b[38;5;241m1\u001b[39m:, :]\n\u001b[0;32m     80\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 81\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size), tgt_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     83\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[181], line 13\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memery_mask)\u001b[0m\n\u001b[0;32m     11\u001b[0m tgt_emb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(tgt)\n\u001b[0;32m     12\u001b[0m memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src_emb,src_mask)\n\u001b[1;32m---> 13\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemery_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(out)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[180], line 36\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, encoder_output, tgt_mask, memery_mask)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,encoder_output,tgt_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,memery_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 36\u001b[0m         x\u001b[38;5;241m=\u001b[39m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemery_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[180], line 19\u001b[0m, in \u001b[0;36mDecodeLayer.forward\u001b[1;34m(self, x, encoder_output, tgt_mask, memory_mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m out1,_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaskedMultiHeadAttention(x,x,x,tgt_mask)\n\u001b[0;32m     18\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out1))\n\u001b[1;32m---> 19\u001b[0m out2,_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out2))\n\u001b[0;32m     21\u001b[0m out3\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff(x)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[177], line 29\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[0;32m     27\u001b[0m batch_size\u001b[38;5;241m=\u001b[39mQ\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     28\u001b[0m Q\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_Q(Q)\u001b[38;5;241m.\u001b[39mview(batch_size,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m K\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_K\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_k\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     30\u001b[0m V\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_V(V)\u001b[38;5;241m.\u001b[39mview(batch_size,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     32\u001b[0m out,attn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(Q,K,V,mask)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[24, -1, 8, 64]' is invalid for input of size 409600"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def data_process(src_data, tgt_data, SRC, TGT):\n",
    "    data = []\n",
    "    for src_line, tgt_line in zip(src_data, tgt_data):\n",
    "        src_tensor = torch.tensor([SRC.vocab.stoi[token] for token in SRC.tokenize(src_line)], dtype=torch.long)\n",
    "        tgt_tensor = torch.tensor([TGT.vocab.stoi[token] for token in TGT.tokenize(tgt_line)], dtype=torch.long)\n",
    "        src_tensor = torch.cat([torch.tensor([SRC.vocab.stoi[\"<bos>\"]]), src_tensor, torch.tensor([SRC.vocab.stoi[\"<eos>\"]])])\n",
    "        tgt_tensor = torch.cat([torch.tensor([TGT.vocab.stoi[\"<bos>\"]]), tgt_tensor, torch.tensor([TGT.vocab.stoi[\"<eos>\"]])])\n",
    "        data.append((src_tensor, tgt_tensor))\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter, tokenizer):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "from torchtext.data import Field\n",
    "\n",
    "\n",
    "\n",
    "# 定义 Field\n",
    "SRC = Field(tokenize=src_tokenizer, init_token=\"<bos>\", eos_token=\"<eos>\", pad_token=\"<pad>\", unk_token=\"<unk>\")\n",
    "TGT = Field(tokenize=tgt_tokenizer, init_token=\"<bos>\", eos_token=\"<eos>\", pad_token=\"<pad>\", unk_token=\"<unk>\")\n",
    "\n",
    "# 构建词汇表\n",
    "SRC.build_vocab(train_en, specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "TGT.build_vocab(train_de, specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "\n",
    "src_vocab = SRC.vocab\n",
    "tgt_vocab = TGT.vocab\n",
    "\n",
    "train_data = data_process(train_en, train_de, SRC, TGT)\n",
    "val_data = data_process(val_en, val_de, SRC, TGT)\n",
    "test_data = data_process(test_en, test_de, SRC, TGT)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(src_sample)\n",
    "        tgt_batch.append(tgt_sample)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=SRC.vocab.stoi[\"<pad>\"])\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=TGT.vocab.stoi[\"<pad>\"])\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 初始化模型\n",
    "vocab_size = len(SRC.vocab)\n",
    "d_model = 512\n",
    "max_len = 100\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(vocab_size, d_model, max_len, num_layers, num_heads, d_ff, dropout, device).to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=SRC.vocab.stoi[\"<pad>\"])\n",
    "\n",
    "# 训练循环\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src_batch, tgt_batch in dataloader:\n",
    "        src_batch, tgt_batch = src_batch.to(device), tgt_batch.to(device)\n",
    "        tgt_input = tgt_batch[:-1, :]\n",
    "        tgt_output = tgt_batch[1:, :]\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(src_batch, tgt_input)\n",
    "        loss = criterion(logits.view(-1, vocab_size), tgt_output.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 训练过程\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(),\"transformer_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e24d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"transformer_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "def greedy_decode(model, src, max_len, start_symbol, device):\n",
    "    src = src.to(device)\n",
    "    memory = model.encoder(model.embedding(src))\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src).to(device)\n",
    "    for i in range(max_len - 1):\n",
    "        out = model.decoder(model.embedding(ys), memory)\n",
    "        prob = model.output_layer(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        ys = torch.cat([ys, next_word.unsqueeze(0)], dim=1)\n",
    "        if next_word.item() == SRC.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "    return ys\n",
    "    \n",
    "def evaluate_bleu(model, dataloader, SRC, TGT, device):\n",
    "    \"\"\"\n",
    "    测试模型并计算 BLEU 分数\n",
    "    :param model: Transformer 模型\n",
    "    :param dataloader: 测试数据加载器\n",
    "    :param SRC: 源语言 Field\n",
    "    :param TGT: 目标语言 Field\n",
    "    :param device: 设备\n",
    "    :return: BLEU 分数\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_bleu = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for src_batch, tgt_batch in dataloader:\n",
    "            src_batch, tgt_batch = src_batch.to(device), tgt_batch.to(device)\n",
    "            for i in range(src_batch.size(1)):\n",
    "                # 贪婪解码生成翻译结果\n",
    "                result = greedy_decode(model, src_batch[:, i], max_len=100, start_symbol=TGT.vocab.stoi[\"<bos>\"], device=device)\n",
    "                candidate = [TGT.vocab.itos[token.item()] for token in result if token.item() not in [TGT.vocab.stoi[\"<pad>\"], TGT.vocab.stoi[\"<bos>\"], TGT.vocab.stoi[\"<eos>\"]]]\n",
    "                reference = [[TGT.vocab.itos[token.item()] for token in tgt_batch[:, i] if token.item() not in [TGT.vocab.stoi[\"<pad>\"], TGT.vocab.stoi[\"<bos>\"], TGT.vocab.stoi[\"<eos>\"]]]]\n",
    "                # 计算 BLEU 分数\n",
    "                total_bleu += compute_bleu(candidate, reference)\n",
    "                num_samples += 1\n",
    "    return total_bleu / num_samples\n",
    "\n",
    "# 计算 BLEU 分数\n",
    "bleu_score = evaluate_bleu(model, test_dataloader, SRC, TGT, device)\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "\n",
    "def print_translations(model, dataloader, SRC, TGT, device, num_samples=5):\n",
    "    \"\"\"\n",
    "    打印模型翻译结果与参考翻译\n",
    "    :param model: Transformer 模型\n",
    "    :param dataloader: 测试数据加载器\n",
    "    :param SRC: 源语言 Field\n",
    "    :param TGT: 目标语言 Field\n",
    "    :param device: 设备\n",
    "    :param num_samples: 打印样本数量\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for src_batch, tgt_batch in dataloader:\n",
    "            src_batch, tgt_batch = src_batch.to(device), tgt_batch.to(device)\n",
    "            for i in range(src_batch.size(1)):\n",
    "                if count >= num_samples:\n",
    "                    return\n",
    "                # 贪婪解码生成翻译结果\n",
    "                result = greedy_decode(model, src_batch[:, i], max_len=100, start_symbol=TGT.vocab.stoi[\"<bos>\"], device=device)\n",
    "                source = [SRC.vocab.itos[token.item()] for token in src_batch[:, i] if token.item() not in [SRC.vocab.stoi[\"<pad>\"], SRC.vocab.stoi[\"<bos>\"], SRC.vocab.stoi[\"<eos>\"]]]\n",
    "                target = [TGT.vocab.itos[token.item()] for token in tgt_batch[:, i] if token.item() not in [TGT.vocab.stoi[\"<pad>\"], TGT.vocab.stoi[\"<bos>\"], TGT.vocab.stoi[\"<eos>\"]]]\n",
    "                prediction = [TGT.vocab.itos[token.item()] for token in result if token.item() not in [TGT.vocab.stoi[\"<pad>\"], TGT.vocab.stoi[\"<bos>\"], TGT.vocab.stoi[\"<eos>\"]]]\n",
    "                print(f\"Source: {' '.join(source)}\")\n",
    "                print(f\"Target: {' '.join(target)}\")\n",
    "                print(f\"Prediction: {' '.join(prediction)}\")\n",
    "                print(\"-\" * 50)\n",
    "                count += 1\n",
    "\n",
    "# 打印翻译结果\n",
    "print_translations(model, test_dataloader, SRC, TGT, device, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
